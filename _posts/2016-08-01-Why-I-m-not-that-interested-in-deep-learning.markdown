---
layout: post
title:  "Why I'm not that interested in deep learning"
date:   2016-08-01 21:00:00
categories: ai dl
---

The reply by "nv-vn" [here](https://news.ycombinator.com/item?id=12200196)
reminds me of how we've lost track about the original purpose of AI. We've lost track so much that we now stick
a 'G' it the middle.

> A lot of the comments here seem to focus only on the progress we've made rather than what AI 
> should be (if it was true to the name). With "AI", sure I can tell Siri to send a certain email to 
> a certain person. That's pretty damn impressive when I think back to what was possible only a few 
> years earlier. But it's not intelligent. Nowhere near. And honestly, it doesn't save you that much 
> work. It just performs some preprogrammed tasks given some unambiguous input that follows a regular
>  pattern. And even that trips up Siri a ton. Yes, it's cool that you can identify pictures or have a
>   program read your handwriting, but none of that gets us any closer to a program that behaves like 
>   a human when I tell it to do something (instead of sending an email or text that I specify, it 
>   could draft one on its own; instead of showing me a Wikipedia article when I ask what something 
>   is it should explain to me in layman's terms and give me a summary). AI is impressive in terms of
>    progress, but is it really impressive in terms of what it promises to bring? Is it really even 
>    progressing in the right direction? Personally, I don't think so.

When working on hard problems, lots of spinoffs and interesting things happen, and it is easy to
[lose track](http://lesswrong.com/lw/le/lost_purposes/) about what it is we are trying to achieve
in the first place. Personally, I'm interested in solving AGI (or, more realistically, trying to).
And doing so requires the following: learning to program, learning maths, information theory,
probability theory, machine learning... Because talent in any of these domains is scarce, continuing
to pursue the original goal means saying no to a lot of opportunities along the way.

That is why I'm not that interested in deep learning: it's a highly valuable skill and achieves 
state-of-the-art performance on
many tasks, but ultimately, it's not much more that machine perception. To solve AGI, 
we will need more than that.